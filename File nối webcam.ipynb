{"cells":[{"cell_type":"markdown","metadata":{"id":"8B0X8cddPGoe"},"source":["![](https://static.wixstatic.com/media/4205be_693bbdf8070b461186014060ec420cc7~mv2.jpg/v1/fill/w_568,h_386,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/4205be_693bbdf8070b461186014060ec420cc7~mv2.jpg)"]},{"cell_type":"markdown","metadata":{"id":"JdLeY1iMPGoh"},"source":["# 1. Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T04:46:40.283161Z","iopub.status.busy":"2025-03-07T04:46:40.282817Z","iopub.status.idle":"2025-03-07T04:47:02.567087Z","shell.execute_reply":"2025-03-07T04:47:02.566244Z","shell.execute_reply.started":"2025-03-07T04:46:40.283121Z"},"trusted":true,"id":"XdVakgx6PGoh"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader, Dataset\n","import cv2\n","import torch.optim as optim\n","import warnings\n","warnings.filterwarnings('ignore')\n","from PIL import Image\n","from tqdm import tqdm\n","\n","# Magic command for displaying plots in Jupyter notebooks\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"_1TghdXPPGoi"},"source":["# 6. Building the CNN Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-07T04:47:56.543564Z","iopub.status.busy":"2025-03-07T04:47:56.543306Z","iopub.status.idle":"2025-03-07T04:47:59.883664Z","shell.execute_reply":"2025-03-07T04:47:59.882889Z","shell.execute_reply.started":"2025-03-07T04:47:56.543541Z"},"trusted":true,"id":"yDgruko-PGoi","outputId":"37757c7b-6087-418e-a5d5-8c8469eceba5"},"outputs":[{"name":"stdout","output_type":"stream","text":["EmotionCNN(\n","  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu1): ReLU()\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout1): Dropout(p=0.25, inplace=False)\n","  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu2): ReLU()\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout2): Dropout(p=0.25, inplace=False)\n","  (conv3): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu3): ReLU()\n","  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout3): Dropout(p=0.25, inplace=False)\n","  (conv4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu4): ReLU()\n","  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout4): Dropout(p=0.25, inplace=False)\n","  (fc1): Linear(in_features=25088, out_features=256, bias=True)\n","  (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu5): ReLU()\n","  (dropout5): Dropout(p=0.25, inplace=False)\n","  (fc2): Linear(in_features=256, out_features=512, bias=True)\n","  (bn6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu6): ReLU()\n","  (dropout6): Dropout(p=0.25, inplace=False)\n","  (fc3): Linear(in_features=512, out_features=7, bias=True)\n",")\n"]}],"source":["class EmotionCNN(nn.Module):\n","    def __init__(self, num_classes=7):\n","        super(EmotionCNN, self).__init__()\n","\n","        # --- CÁC LỚP TÍCH CHẬP GIỮ NGUYÊN ---\n","        # Block 1\n","        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.dropout1 = nn.Dropout(0.25)\n","\n","        # Block 2\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.dropout2 = nn.Dropout(0.25)\n","\n","        # Block 3\n","        self.conv3 = nn.Conv2d(128, 512, kernel_size=3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(512)\n","        self.relu3 = nn.ReLU()\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.dropout3 = nn.Dropout(0.25)\n","\n","        # Block 4\n","        self.conv4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n","        self.bn4 = nn.BatchNorm2d(512)\n","        self.relu4 = nn.ReLU()\n","        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.dropout4 = nn.Dropout(0.25)\n","\n","        # --- CÁC LỚP KẾT NỐI ĐẦY ĐỦ (DENSE LAYERS) ---\n","\n","        # <<< THAY ĐỔI QUAN TRỌNG Ở ĐÂY >>>\n","        # Kích thước đầu vào của lớp fc1 được cập nhật cho ảnh 112x112\n","        # Kích thước sau 4 lớp pooling: 112 -> 56 -> 28 -> 14 -> 7.\n","        # Kích thước vector phẳng = 512 (kênh) * 7 * 7 = 25088\n","        self.fc1 = nn.Linear(512 * 7 * 7, 256)\n","\n","        self.bn5 = nn.BatchNorm1d(256)\n","        self.relu5 = nn.ReLU()\n","        self.dropout5 = nn.Dropout(0.25)\n","\n","        self.fc2 = nn.Linear(256, 512)\n","        self.bn6 = nn.BatchNorm1d(512)\n","        self.relu6 = nn.ReLU()\n","        self.dropout6 = nn.Dropout(0.25)\n","\n","        # Output layer\n","        self.fc3 = nn.Linear(512, num_classes)\n","\n","\n","    def forward(self, x):\n","        # --- LUỒNG DỮ LIỆU ĐI TIẾP VẪN GIỮ NGUYÊN ---\n","        # Conv block 1\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu1(x)\n","        x = self.pool1(x)\n","        x = self.dropout1(x)\n","\n","        # Conv block 2\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu2(x)\n","        x = self.pool2(x)\n","        x = self.dropout2(x)\n","\n","        # Conv block 3\n","        x = self.conv3(x)\n","        x = self.bn3(x)\n","        x = self.relu3(x)\n","        x = self.pool3(x)\n","        x = self.dropout3(x)\n","\n","        # Conv block 4\n","        x = self.conv4(x)\n","        x = self.bn4(x)\n","        x = self.relu4(x)\n","        x = self.pool4(x)\n","        x = self.dropout4(x)\n","\n","        # Flatten\n","        x = torch.flatten(x, 1)\n","\n","        # Dense layers\n","        x = self.fc1(x)\n","        x = self.bn5(x)\n","        x = self.relu5(x)\n","        x = self.dropout5(x)\n","\n","        x = self.fc2(x)\n","        x = self.bn6(x)\n","        x = self.relu6(x)\n","        x = self.dropout6(x)\n","\n","        # Output layer\n","        x = self.fc3(x)\n","\n","        return x\n","\n","# --- CÁC PHẦN KHỞI TẠO KHÁC GIỮ NGUYÊN ---\n","# Khởi tạo mô hình\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = EmotionCNN(num_classes=7).to(device)\n","\n","# Định nghĩa optimizer và loss function\n","# Thêm L2 regularization thông qua weight_decay\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","# In ra cấu trúc model để kiểm tra\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"E5C9av_SPGoj"},"source":["# 9. Evaluating the Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUOFmDxpPGoj"},"outputs":[],"source":["# 2. Cấu hình\n","MODEL_PATH = 'best_model.pth' # <<< Sửa lại tên file .pth cho đúng\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","EMOTION_LABELS = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n","\n","# 3. Tải model\n","model = EmotionCNN().to(DEVICE)\n","model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n","model.eval()\n","\n","# 4. Định nghĩa transform\n","transform = transforms.Compose([\n","    transforms.Resize((112, 112)),\n","    transforms.Grayscale(num_output_channels=1),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5], [0.5])\n","])\n","\n","# 5. Khởi tạo webcam và bộ dò tìm khuôn mặt\n","cap = cv2.VideoCapture(0)\n","face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","\n","# <<< THÊM MỚI: Biến để kiểm soát việc lật camera >>>\n","flip_frame = False\n","\n","# --- VÒNG LẶP CHÍNH ---\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        print(\"Không thể đọc frame từ webcam.\")\n","        break\n","\n","    # <<< CẢI TIẾN: Lật camera nếu biến flip_frame là True >>>\n","    if flip_frame:\n","        frame = cv2.flip(frame, 1) # Lật theo trục dọc\n","\n","    # Xử lý phím bấm\n","    key = cv2.waitKey(1) & 0xFF\n","\n","    # Nhấn 'q' để thoát\n","    if key == ord('q'):\n","        break\n","\n","    # <<< CẢI TIẾN: Nhấn 'f' để bật/tắt chế độ lật camera >>>\n","    if key == ord('f'):\n","        flip_frame = not flip_frame\n","\n","    # Chuyển sang ảnh xám để dò tìm\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n","\n","    # Xử lý từng khuôn mặt tìm được\n","    for (x, y, w, h) in faces:\n","        # Vẽ khung chữ nhật quanh khuôn mặt\n","        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n","\n","        # Cắt riêng vùng khuôn mặt\n","        face_roi = frame[y:y+h, x:x+w]\n","\n","        # Chuyển đổi và áp dụng transform\n","        pil_image = Image.fromarray(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))\n","        image_tensor = transform(pil_image).unsqueeze(0).to(DEVICE)\n","\n","        # Dự đoán cảm xúc\n","        with torch.no_grad():\n","            output = model(image_tensor)\n","\n","            # <<< CẢI TIẾN: Sử dụng Softmax để lấy xác suất phần trăm >>>\n","            probabilities = torch.nn.functional.softmax(output, dim=1)[0] # Lấy tensor xác suất\n","\n","            # Lấy cảm xúc có xác suất cao nhất để hiển thị chính\n","            confidence, predicted_idx = torch.max(probabilities, 0)\n","            main_emotion = EMOTION_LABELS[predicted_idx.item()]\n","            main_confidence = confidence.item()\n","\n","        # Hiển thị cảm xúc chính lên trên khung chữ nhật\n","        main_text = f\"{main_emotion} ({main_confidence:.2f})\"\n","        cv2.putText(frame, main_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n","\n","        # <<< CẢI TIẾN: Hiển thị tất cả các phần trăm ở góc màn hình >>>\n","        # Tạo một background mờ để dễ đọc chữ\n","        overlay = frame.copy()\n","        cv2.rectangle(overlay, (10, 10), (250, 220), (0, 0, 0), -1)\n","        alpha = 0.6  # Độ trong suốt\n","        cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n","\n","        # In từng dòng cảm xúc và phần trăm\n","        for i, (label, prob) in enumerate(zip(EMOTION_LABELS, probabilities)):\n","            text = f\"{label}: {prob.item():.2%}\"\n","            text_y = 30 + i * 28 # Vị trí y cho mỗi dòng\n","\n","            # Highlight cảm xúc có % cao nhất\n","            text_color = (0, 255, 0) if label == main_emotion else (255, 255, 255)\n","\n","            cv2.putText(frame, text, (20, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n","\n","\n","    # Hiển thị khung hình\n","    cv2.imshow('Emotion Detection', frame)\n","\n","# Dọn dẹp\n","cap.release()\n","cv2.destroyAllWindows()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":786787,"sourceId":1351797,"sourceType":"datasetVersion"}],"dockerImageVersionId":30919,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}